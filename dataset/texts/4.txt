%%
%% This is file `paper.tex', 
%% Sample file for ALGORITMY 2024 macros for use with LaTeX 2e
%% based on SIAM macros 
%% 
%% Modified by Daniel Sevcovic 2015

%\documentclass[final]{algoritmy}
\documentclass{algoritmy}

\usepackage{graphicx,amsmath,amssymb}

% definitions used by included articles, reproduced here for 
% educational benefit, and to minimize alterations needed to be made
% in developing this sample file.

\newcommand{\pe}{\psi}
\def\d{\delta} 
\def\ds{\displaystyle} 
\def\e{{\epsilon}} 
\def\eb{\bar{\eta}}  
\def\enorm#1{\|#1\|_2} 
\def\Fp{F^\prime}  
\def\fishpack{{FISHPACK}} 
\def\fortran{{FORTRAN}} 
\def\gmres{{GMRES}} 
\def\gmresm{{\rm GMRES($m$)}} 
\def\Kc{{\cal K}} 
\def\norm#1{\|#1\|} 
\def\wb{{\bar w}} 
\def\zb{{\bar z}} 

% some definitions of bold math italics to make typing easier.
% They are used in the corollary.

%\def\bfE{\mbox{\boldmath$E$}}
%\def\bfG{\mbox{\boldmath$G$}}

\title{Best polynomial approximation for non-autonomous linear ODEs in the $\star$-product framework\thanks{This work was supported by Charles University Research Centre program No. PRIMUS/21/SCI/009 and UNCE/24/SCI/005, and by the Magica project ANR-20-CE29-0007 funded by the French National Research Agency.}}

% The thanks line in the title should be filled in if there is
% any support acknowledgement for the overall work to be included
% This \thanks is also used for the received by date info, but
% authors are not expected to provide this.

\author{Stefano Pozza\thanks{Faculty of Mathematics and Physics, Charles University, SokolovskÃ¡ 83, 186 75 Praha 8, Czech Republic,({\tt pozza@karlin.mff.cun.cz}).}}

\begin{document}


%% Start and end pages of the document. Do not chenge
\AlgLogo{1}{10}



\maketitle

\begin{abstract}
We present the first formulation of the optimal polynomial approximation of the solution of linear non-autonomous systems of ODEs in the framework of the so-called $\star$-product. This product is the basis of new approaches for the solution of such ODEs, both in the analytical and the numerical sense.
The paper shows how to formally state the problem and derives upper bounds for its error.
\end{abstract}

\begin{keywords} 
Non-autonomous linear ODEs, polynomial approximation, error analysis, 
\end{keywords}

\begin{AMS}
46F10, 37C60, 65L05
\end{AMS}

\pagestyle{myheadings}
\thispagestyle{plain}
\markboth{S. Pozza}{POLYNOMIAL APPROXIMATION IN THE $\star$-FRAMEWORK}

\section{Introduction}
Recently, a new approach has been introduced for the solution of systems of linear non-autonomous ordinary differential equations based on the so-called $\star$-product \cite{GiLuThJa15,GisPozInv19,Po23,Ry23}. Such an approach has proved to be valuable and effective analytically, by producing new explicit expressions for the solution of certain problems \cite{BonGis2020,GiLuThJa15,GiPo20}, and numerically, being the basis of new efficient algorithms in quantum chemistry problems \cite{BoPoVB23,PoVB24,PoVB23_PAMM_B,PoVB23_PAMM_A}. 

Given a Hermitian matrix-valued function $\tilde{A}(t) \in \mathbb{C}^{N \times N}$ analytic on the bounded interval $I$, and the nonzero vector $\tilde{v}\in \mathbb{C}^{N \times N}$ we consider the initial value problem
    \begin{equation}\label{eq:ode}
        \frac{\partial}{\partial t}\tilde{u}(t) = \tilde{A}(t)\tilde{u}(t), \quad \tilde{u}(a) = \tilde{v}, \quad t \in I=[a, b].
    \end{equation} 
The $\star$-product is defined over a FrÃ©chet-Lie group on distributions \cite{Ry23}. In such a group, the initial value problem becomes a \emph{$\star$-linear system}. Thanks to this ``linearization'' of the ODE, new techniques can be applied to solve the problem. Here, we focus on the polynomial approximation approach, which can be used both in numerical approaches and in the theoretical framework. In particular, in the latter one, a symbolic algorithm named $\star$-Lanczos \cite{GiPo20} is able to produce a Krylov-like subspace approximation, that is, a polynomial approximation in the $\star$-product sense.

In this work, we will show that it is possible to formulate the problem of a best polynomial approximation for $\tilde{u}$ in the $\star$-framework. Moreover, we will show that its error can be bounded by the best uniform norm polynomial approximation error for the exponential \cite{meinardus}. This result is crucial to understand the numerical behavior of polynomial-based numerical methods when solving linear systems derived by using the $\star$-approach. Indeed, the polynomial approximation is central in the analysis of standard Krylov subspace methods (e.g., \cite{liestr}), and its extension to the $\star$-framework will also allow extending this kind of numerical analysis.

In Section~\ref{sec:basics}, we introduce the basics of the $\star$-product, and we state the main result. Section~\ref{sec:mtx} shows how to extend matrix analysis results to the $\star$-framework. The prove of the main result is given in Section~\ref{sec:app} and Section~\ref{sec:conc} draw some conclusions.

\begin{table}
\caption{List of the main $\star$-definitions and related objects, $f,g, x$ are generally from $\mathcal{A}(I)$.}
\begin{center} \footnotesize
\begin{tabular}{|c|c|c|c|} \hline  
%&& Number of & Number of & Mean Run Time & Standard \\ 
Name & Symbol & Definition & Comments / Properties \\ \hline 
\lower 1ex\hbox{$\star$-product} & \lower 1ex\hbox{$f \star g$} &  \lower 1ex\hbox{$\int_I f(t,\tau) g(\tau,s) \text{d}\tau $} & \lower 1ex\hbox{} \\
\lower 1ex\hbox{$\star$-identity}  &  \lower 1ex\hbox{$\delta$} & \lower 1ex\hbox{$f \star \delta = \delta \star f = f$} & \lower 1ex\hbox{$\delta(t-s)$: Dirac delta}  \\ 
\lower 1ex\hbox{$\star$-inverse} & \lower 1ex\hbox{$f^{-\star}$} & \lower 1ex\hbox{$f \star f^{-\star} = f^{-\star} \star f = \delta$} & \lower 1ex\hbox{Existence \cite{GisPozInv19,Ry23}} \\ 
\lower 1ex\hbox{Heaviside function} & \lower 1ex\hbox{$\Theta$} & \lower 1ex\hbox{$\Theta(t-s) = 1, t \geq s$, $0$ otherwise} &  \\ 
\lower 1ex\hbox{Analytic $\Theta$-set} & \lower 1ex\hbox{$\mathcal{A}_\Theta(I)$} & \lower 1ex\hbox{{\{$\tilde{f}(t,s)\Theta(t-s)$:  $\tilde{f}$ analytic on $I^2$\}}} & \lower 1ex\hbox{$\star$-product-closed set}\\ 
\lower 1ex\hbox{Dirac 1st derivative} & \lower 1ex\hbox{$\delta'$} & \lower 1ex\hbox{$\delta'(t-s)$} & \lower 1ex\hbox{$\delta'\star \Theta = \Theta \star \delta' = \delta$}  \\ 
\lower 1ex\hbox{Dirac derivatives} & \lower 1ex\hbox{$\delta^{(j)}$} & \lower 1ex\hbox{$\delta^{(j)}(t-s)$} & \lower 1ex\hbox{$\delta^{(j)}\star \delta^{(i)} = \delta^{(i+j)}$}  \\ 
\lower 1ex\hbox{$\star$-powers} & \lower 1ex\hbox{$f^{\star j}$} & \lower 1ex\hbox{$f \star f \star \cdots \star f$, $j$ times} & \lower 1ex\hbox{$f^{\star 0}:= \delta$, by convention}  \\ 
\lower 1ex\hbox{$\star$-resolvent} & \lower 1ex\hbox{$R^\star(x)$} &  \lower 1ex\hbox{$\sum_{j=0}^\infty x^{\star j}, \, x \in \mathcal{A}_\Theta(I)$}  & \lower 1ex\hbox{$R^\star(x) = (\delta-x)^{-\star}$} \\ 
\lower 1ex\hbox{$\star$-polynomial} & \lower 1ex\hbox{$p^\star(x)$} & \lower 1ex\hbox{$\sum_{j=0}^n \alpha_j x^{\star j}$, $\alpha_j \in \mathbb{C}$} & \lower 1ex\hbox{if $\alpha_n \neq 0$, $n$ is the degree} \\ 
\hline  
\end{tabular}
\end{center} 
\label{tab:stardef} 
\end{table}  

\begin{table}
\caption{Useful properties of $\star$-product actions on $\mathcal{A}_\Theta(I)$ elements.}
\begin{center} \footnotesize
\begin{tabular}{|c|c|c|c|} \hline  
 Description  & Definition & Property \\ \hline 
\lower 1ex\hbox{``Integration'' in $t$} & \lower 1ex\hbox{$\tilde{F}\Theta$, $\tilde{F}(t,s)$ primitive of $\tilde{f}$  in $t$, $F(s,s)=0$}  & \lower 1ex\hbox{$\tilde{F}\Theta = \Theta \star \tilde{f}\Theta$}  \\ 
\lower 1ex\hbox{``Integration'' in $s$} & \lower 1ex\hbox{$\tilde{F}\Theta$, $\tilde{F}(t,s)$ primitive of $\tilde{f}$  in $s$, $\tilde{F}(t,t)=0$}  & \lower 1ex\hbox{$\tilde{F}\Theta = \tilde{f}\Theta \star \Theta $}  \\ 
\lower 1ex\hbox{``Differentiation'' in $t$} & \lower 1ex\hbox{$\tilde{f}^{(1,0)}\Theta$, $\tilde{f}^{(1,0)}(t,s)$ derivative of $\tilde{f}$  in $t$}  & \lower 1ex\hbox{$\delta'\star \tilde{f}\Theta = \tilde{f}^{(1,0)}\Theta + \tilde{f}\delta $}  \\ 
\lower 1ex\hbox{``Differentiation'' in $s$} & \lower 1ex\hbox{$\tilde{f}^{(0,1)}\Theta$, $\tilde{f}^{(0,1)}(t,s)$ derivative of $\tilde{f}$  in $s$}  & \lower 1ex\hbox{$\tilde{f}\Theta \star \delta' = -\tilde{f}^{(0,1)}\Theta + \tilde{f}\delta $}  \\ 
\hline  
\end{tabular}
\end{center} 
\label{tab:starprop} 
\end{table}  


\section{Basics and main result}\label{sec:basics}
In order to state the main result, we first summarize the $\star$-product basics. Refer to \cite{Ry23} for the general definition of this product and the related properties.
Given a bounded interval $I$, let us denote with $\mathcal{A}(I)$ the set of the bivariate distributions of the kind
\begin{equation*}
    f(t,s) = \tilde{f}_{-1}(t,s)\Theta(t-s) + \tilde{f}_{0}(t)\delta(t-s) + \tilde{f}_{1}(t)\delta'(t-s) + \dots + \tilde{f}_{k}(t)\delta^{(k)}(t-s),
\end{equation*}
where $\tilde{f}_{-1}, \dots, \tilde{f}_{k}$ are analytic functions over $I$ both in $t$ and $s$, $\Theta$ is the Heaviside function ($\Theta(t-s) = 1$ for $t \geq s$, and $0$ otherwise), and $\delta, \delta', \dots, \delta^{(k)}$ are the Dirac delta and its derivatives.
Then, the $\star$-product of $f_1, f_2 \in \mathcal{A}(I)$ is
\begin{equation*}
    (f_1 \star f_2)(t,s) := \int_I f_1(t,\tau) f_2(\tau,s) \,\text{d}\tau \in \mathcal{A}(I).
\end{equation*}
Some of the important properties, definitions, and facts about the $\star$-product can be found in Tables~\ref{tab:stardef} and \ref{tab:starprop}.
Specifically, it is easy to see that $\delta(t-s)$ is the $\star$-product identity. Moreover, since $\mathcal{A}(I)$ is closed under $\star$-product, we can define the $\star$-powers of $f \in \mathcal{A}(I)$, denoted as $f^{\star n}$ with the convention $f^{\star 0}= \delta$. Therefore, for $x \in \mathcal{A}(I)$, we can define the \emph{$\star$-polynomial of degree $n$} as \begin{equation}
    p^\star(t,s) := \alpha_0 \delta(t-s) + \alpha_1 x(t,s) + \alpha_2 x(t,s)^{\star 2} + \dots + \alpha_n x(t,s)^{\star n}, 
\end{equation}
with constants $\alpha_0, \dots, \alpha_n \in \mathbb{C}$, $\alpha_n \neq 0$. We call $\mathcal{P}^\star_n$ the set of all such $\star$-polynomials.

We define the subset $\mathcal{A}_\Theta(I) \subset \mathcal{A}(I)$ of the distributions of the form $f(t,s)=\tilde{f}(t,s)\Theta(t-s)$, with $\tilde{f}$ a function analytic over $I^2$. The \emph{$\star$-resolvent} is defined as
\begin{equation*}
    R^\star(x) := \sum_{j=0}^\infty x^{\star j}.    
\end{equation*}
Note that $R^\star(x)$ is well-defined (i.e., convergent) for every $x \in \mathcal{A}_\Theta$ \cite{GiLuThJa15}.

When $A, B$ are matrices with compatible sizes composed of elements from $\mathcal{A}(I)$, the $\star$-product straightforwardly extends to a matrix-matrix (or matrix-vector) $\star$-product. In the following, we denote with $\mathcal{A}^{N \times M}(I)$ and $\mathcal{A}_\Theta^{N \times M}(I)$ the spaces of $N \times M$ matrices with elements from those sets. We denote with $I_\star = \tilde{I} \delta(t-s)$ the identity matrix in $\mathcal{A}^{N \times N}(I)$, with $\tilde{I}$ the standard $N \times N$ identity matrix.

Setting $I = [a,b]$, the solution $\tilde{u}(t)$ of the ODE \eqref{eq:ode} can be expressed by
\begin{equation}\label{eq:starsolres}
    \tilde{u}(t) = U(t,a)\tilde{v}, \; t\in I, \quad U(t,s) = \Theta(t-s) \star R^{\star}\left(\tilde{A}(t)\Theta(t-s)\right);
\end{equation}
as proven in \cite{GiLuThJa15}.
From now on, we will skip the distribution arguments $t,s$ whenever it is useful and clear from the context.
Since $R^{\star}(\tilde{A}\Theta)$ is the $\star$-inverse of $I_\star - \tilde{A}\Theta$ (e.g., \cite{Po23}), then solving \eqref{eq:starsolres} means solving the system of $\star$-linear equations
\begin{equation*}
    (I_\star - \tilde{A}\Theta) \star x = \tilde{v}\delta, \quad \tilde{u}(t) = (\Theta \star x)(t,a) \quad t \in I.
\end{equation*}
Note that this is not just a theoretical result since there is an efficient way to transform the $\star$-linear system into a usual linear system that can be solved numerically \cite{PoVB24,PoVB23_PAMM_B,PoVB23_PAMM_A}.

It is reasonable to consider a $\star$-polynomial approximation $p^\star(\tilde{A}\Theta)\tilde{v} \approx R^\star(\tilde{A}\Theta)\tilde{v}$.
Specifically, we aim at finding the best $\star$-polynomial $p^\star(t,s)$ of degree $n$ that approximates the $\star$-resolvent $R^\star(A)\tilde{v}$ in the $L_2$ norm sense, i.e., the polynomial $q^\star$ that minimizes the error
\begin{equation*}
        \|\tilde{u}(t) - (\Theta \star q^\star(A)\tilde{v})(t,a) \|_{L_2} := \left(\int_{a}^b | \tilde{u}(\tau) - (\Theta \star q^\star(A))(\tau, a) \tilde{v} |^2 \right)^{\frac{1}{2}}, \; t \in I.
\end{equation*}
Note that $\Theta \star q^\star(A) \in \mathcal{A}_\Theta^{N \times N}$, while $q^\star(A) \in \mathcal{A}^{N \times N}$.


\begin{theorem}[Main result]\label{thm:main}
    Consider the initial value problem \eqref{eq:ode}
    and let $\tilde{\lambda}_1(t), \dots, \tilde{\lambda}_N(t)$ be the eigenvalues of
    $\tilde{A}(t) \in \mathbb{C}^{N \times N}$.
    We define the interval 
    \begin{equation*}
        J := \left[\min_{t \in I, i=1,\dots, N} \tilde{\lambda}_i(t), \max_{t \in I, i=1,\dots, N} \tilde{\lambda}_i(t)\right] \times \emph{length}(I),
    \end{equation*}
    and denote with $E_n(J)$ the minimal uniform error of the polynomial approximation of the exponential over $J$, i.e.,
    \begin{equation*}
        E_n(J) := \min_{p \in \mathcal{P}_n} \max_{t \in J} |\exp(t) - p(t)|.
    \end{equation*}
    Define $A(t,s) = \tilde{A}(t)\Theta(t-s)$. Then the error of the $L_2$-best $\star$-polynomial approximant $q^\star$ can be bounded by
    \begin{equation*}
        \|\tilde{u}(t) - (\Theta \star q^\star(A)\tilde{v})(t,a) \|_{L_2} \leq E_n(J) \leq M \rho^{n+1}, \; t \in I
    \end{equation*} 
    for some constant $M>0$ and $0<\rho<1$ depending on $J$.
\end{theorem}


%\subsection{$\star$-monomials}
%Let $x(t,s)= \tilde{x}(t)\Theta(t-s) \in \mathcal{A}_\Theta$. Then, we can define the $\star$-powers $x(t,s)^{\star 0} = \delta(t-s), x(t,s)^{\star 1}, x(t,s)^{\star 2}, \dots$ which can also be interpreted as $\star$-monomials. 
%By taking the linear combination of $\star$-monomials with respect to the usual product, we obtain the definition of a $\star$-polynomial of degree $n$ as\footnote{Note that, we can equivalently define a $\star$-polynomial as the linear combination of the $\star$-monomials with respect to the $\star$-product if we use as coefficients of the combination elements of the kind $\alpha_j\delta(t-s)$, where $\alpha_j$ is a constant.}:
%\begin{equation}
 %   p^\star(t,s) = \alpha_0 \delta(t-s) + \alpha_1 x(t,s) + \alpha_2 x(t,s)^{\star 2} + \dots + \alpha_2 x(t,s)^{\star n}, 
%\end{equation}
%where $\alpha_0, \dots, \alpha_n$ are constants. We call the set of all such $\star$-polynomials $\mathcal{P}^\star_n$.

%Consider the $\star$-resolvent $R^\star(x):=(\delta - x)^{-\star}$ of the function $x(t,s)=\tilde{x}(t)\Theta(t-s)\in\mathcal{A}_\Theta$. 
%We know that it can be equivalently given in terms of the expansion
%$$ R^\star(x) = \sum_{j=0}^\infty x^{\star j}. $$
%It can be approximated by the truncated series
%$$ R^\star_n(x) := \sum_{j=0}^n x^{\star j} \approx R^\star(x), $$
%is hence a $\star$-polynomial whose error is given by 
%$$  \left(R^\star(x) - R^\star_n(x)\right)(t,s) = \sum_{j=n+1}^\infty x(t,s)^{\star j}. $$
%It is, therefore, natural to wonder if there exists another $n$-degree $\star$-polynomial minimizing (in some sense) the error.

\bigskip

The proof of this Theorem will be the outcome of the rest of the paper. The first step towards the proof is to derive an explicit form for the $\star$-monomials $f^{\star n}$ in the case in which $f(t,s)=\tilde{f}(t)\Theta(t-s) \in \mathcal{A}_\Theta(I)$.
\begin{lemma}\label{lemma:npower}
  Consider the function $f(t,s)= \tilde{f}(t)\Theta(t-s) \in \mathcal{A}_\Theta$ and let $\tilde{F}(t)$ be a primitive of $\tilde{f}(t)$. Then, for $ n=1, 2, \dots$, 
  \begin{align}\label{eq:npower:exp}
        f(t,s)^{\star n} &= \frac{\tilde{f}(t)}{(n-1)!} \left(\tilde{F}(t)-\tilde{F}(s)\right)^{n-1} \Theta(t-s),  \\
        \label{eq:thetanpower:exp}
        \Theta(t-s) \star f(t,s)^{\star n} &= \frac{1}{n!} \left(\tilde{F}(t)-\tilde{F}(s)\right)^{n} \Theta(t-s).
  \end{align}
  Moreover, $\Theta(t-s) \star f(t,s)^{\star 0} = \Theta(t-s)$ since $f(t,s)^{\star 0}=\delta(t-s)$ by convention.
\end{lemma}
\begin{proof}
     For $n=2$, the expression~\eqref{eq:npower:exp} is trivially obtained by
    \begin{equation*}
        f(t,s)^{\star 2} = \tilde{f}(t)\Theta(t-s) \int_s^t \tilde{f}(\tau) \,\textrm{d}\tau = \tilde{f}(t)\left(\tilde{F}(t)-\tilde{F}(s)\right)\Theta(t-s).
    \end{equation*}
    Now, by induction, assuming \eqref{eq:npower:exp} we get
    \begin{align}\label{eq:lemma:npower:1}
        f(t,s)^{\star n+1} = \frac{\tilde{f}(t)}{(n-1)!}\Theta(t-s) \int_s^t \tilde{f}(\tau)  \left(\tilde{F}(\tau)-\tilde{F}(s)\right)^{n-1} \textrm{d}\tau.
    \end{align}
    Integrating by part gives
    \begin{align*}
         \int_s^t \tilde{f}(\tau)  \left(\tilde{F}(\tau)-\tilde{F}(s)\right)^{n-1} \textrm{d}\tau &= %\Big[ (\tilde{F}(\tau)- \tilde{F}(s)) (\tilde{F}(\tau)- \tilde{F}(s))^{n-1} \Big]_s^t  - \\
         %& (n-1) \int_s^t  \tilde{f}(\tau)\left(\tilde{F}(\tau)- \tilde{F}(s)\right)^{n-1} \,\textrm{d}\tau \\ 
          (\tilde{F}(t)- \tilde{F}(s))^{n}  - \\ 
         & (n-1) \int_s^t  \tilde{f}(\tau)\left(\tilde{F}(\tau)- \tilde{F}(s)\right)^{n-1} \,\textrm{d}\tau.
    \end{align*}
    Therefore,
    \begin{align*}
         n \int_s^t \tilde{f}(\tau)  \left(\tilde{F}(\tau)-\tilde{F}(s)\right)^{n-1} \textrm{d}\tau &=  (\tilde{F}(t)- \tilde{F}(s))^{n}.
    \end{align*}
    Together with \eqref{eq:lemma:npower:1}, this proves \eqref{eq:npower:exp}.
    Eq.~\eqref{eq:thetanpower:exp} comes from observing that
    \begin{align*}
        \Theta(t-s) \star f(t,s)^{\star n} &= \Theta(t-s) \star \frac{\tilde{f}(t)}{(n-1)!} \left(\tilde{F}(t)-\tilde{F}(s)\right)^{n-1} \Theta(t-s) \\
        &= \frac{\Theta(t-s)}{(n-1)!} \int_s^t \tilde{f}(\tau) \left(\tilde{F}(\tau)-\tilde{F}(s)\right)^{n-1} \textrm{d}\tau \\
        &= \frac{1}{n!} (\tilde{F}(t)- \tilde{F}(s))^{n} \Theta(t-s),
    \end{align*}
    which concludes the proof.
\end{proof}

An immediate consequence of Lemma~\ref{lemma:npower} is that
\begin{equation*}
    \exp\left(\tilde{F}(t) -\tilde{F}(s)\right) = \Theta(t-s) \star R^{\star}(f)(t,s),
\end{equation*}
a well-known result; see, e.g., \cite{GiLuThJa15}.

\section{Matrix spectral decomposition and the $\star$-product}\label{sec:mtx}
%In this Section, we will immerse the spectral decomposition of an analytic Hermitian matrix-valued function in the $\star$-product framework.
Consider a time-dependent $N \times N$ Hermitian matrix-valued function $\tilde{A}(t)$ analytic over the closed interval $I$. Then, for every $t \in I$ there exist matrix-valued functions $\tilde{Q}(t)$ and $\tilde{\Lambda}(t)$ analytic over $I$ such that:
\begin{equation}\label{eq:eigedeco}
\tilde{A}(t) = \tilde{Q}(t) \tilde{\Lambda}(t) \tilde{Q}(t)^H, \text{ with } \tilde{\Lambda}(t) = \text{diag}(\tilde{\lambda}_1(t), \dots, \tilde{\lambda}_n(t)), \; \tilde{Q}(t)^H \tilde{Q}(t) = I,    
\end{equation}
for every $t \in I$; see \cite[Chapter II, Section 6]{kato} (we refer to \cite{dieci99} for extensions to the non-analytic case). The elements of the diagonal matrix $\tilde{\Lambda}(t)$ are analytic functions and, for every $t\in I$, the $\tilde{\lambda}_j(t)$ are the eigenvalues (eigencurves) of $\tilde{A}(t)$.  The columns of $\tilde{Q}(t)$, denoted $\tilde{q}_1(t), \dots, \tilde{q}_N(t)$, are the corresponding eigenvectors (analytic over $I$).

%Now, we aim to define the eigendecomposition in the $\star$-algebra. Generally speaking, 
Given $A(t,s) \in \mathcal{A}_\Theta^{N \times N}(I)$, the $\star$-eigenproblem is to find the $\star$-eigenvalues $\lambda(t,s)\in \mathcal{A}_\Theta(I)$ and the $\star$-eigenvector $q(t,s) \in \mathcal{A}^{N \times 1}(I)$ such that 
\begin{equation}\label{eq:stareig}
    A(t,s) \star q(t,s) = \lambda(t,s) \star q(t,s).
\end{equation}
If $\lambda(t,s)$ and $q(t,s)$ exist, then $q(t,s) \star a(t,s)$ is also a $\star$-eigenvector, for every $a(t,s)\not\equiv 0$ from $\mathcal{A}(I)$. 
%Moreover, note that, since the elements of $A$ are from $\mathcal{A}_\Theta(I)$ we want the $\star$-eigenvalues to be also from $\mathcal{A}_\Theta(I)$. 
For the specific case of interest, where $A(t,s)=\tilde{A}(t)\Theta(t-s)$, the solution to the $\star$-eigenproblem is in the following theorem.
\begin{theorem}\label{thm:stareig}
    Let $A(t,s) = \tilde{A}(t)\Theta(t-s)$ be in $\mathcal{A}_\Theta(I)$, and let $\tilde{\lambda}_i(t)$ and $\tilde{q}_i(t)$, be the (analytic) eigencurves and the corresponding eigenvectors as defined in \eqref{eq:eigedeco} for $i=1,\dots, N$. Then, the solution to the $\star$-eigenvalue problem \eqref{eq:stareig} is given by
    \begin{equation*}
        \lambda_i(t,s) = \tilde{\lambda}_i(t)\Theta(t-s), \quad q_i(t,s) = \tilde{q}_i'(t)\Theta(t-s) + \tilde{q}_i(t) \delta(t-s), \quad i=1,\dots, N.
    \end{equation*}
    where $\tilde{q}_i'(t)$ is the derivative of $\tilde{q}_i(t)$.
\end{theorem}
\begin{proof}
First, note that 
\begin{align*}
    \tilde{\lambda}_i(t) \delta(t-s) \star \tilde{q}_i(t) \Theta(t-s) &= \tilde{\lambda}_i(t) \int_I \delta(t-\tau) \tilde{q}_i(\tau) \Theta(\tau-s) \, \text{d}\tau \\
        &= \tilde{\lambda}_i(t) \tilde{q}_i(t) \Theta(t-s) = \tilde{A}(t) \tilde{q}_i(t) \Theta(t-s) \\
        &= \tilde{A}(t) \delta(t-s) \star \tilde{q}_i(t) \Theta(t-s).
\end{align*}
Using the fact that $\tilde{\lambda}_i(t) \delta(t-s) \star \Theta(t-s) = \tilde{\lambda}_i(t) \Theta(t-s)$, and that $\delta'(t-s) \star \Theta(t-s) = \Theta(t-s) \star \delta'(t-s) = \delta(t-s)$, see Table~\ref{tab:stardef}, we obtain (we omit the variables for the sake of readability)
\begin{align*}
    \tilde{\lambda}_i \delta \star \tilde{q}_i \Theta &=  \tilde{\lambda}_i \delta \star \Theta \star \delta' \star \tilde{q}_i \Theta = \tilde{\lambda}_i \Theta \star \delta' \star \tilde{q}_i \Theta = \tilde{\lambda}_i \Theta \star q_i,
\end{align*}
where $q_i(t,s):= \delta'(t-s) \star \tilde{q}_i(t) \Theta(t-s)$. Similarly, $\tilde{A} \delta \star \tilde{q}_i \Theta = \tilde{A}\Theta \star q_i$. Combining these results, we get
\begin{align*}
    \tilde{\lambda}_i \Theta \star q_i = \tilde{\lambda}_i \delta \star \tilde{q}_i \Theta = \tilde{\lambda}_i \tilde{q}_i \Theta = \tilde{A} \tilde{q}_i \Theta = \tilde{A} \delta \star \tilde{q}_i \Theta = \tilde{A}\Theta \star q_i. 
\end{align*}
Finally, we obtain the following expression for the $\star$-eigenvectors:
\begin{align*}
    q_i(t,s) &= \delta'(t-s) \star \tilde{q}_i(t)\Theta(t-s) \\
    &= \tilde{q}_i'(t)\Theta(t-s) + \tilde{q}_i(t) \delta(t-s);
\end{align*}
see Table~\ref{tab:starprop}.
As a final remark, note that all the $\star$-products are well-defined thanks to the fact that the $\tilde{\lambda}_i(t)$ and $\tilde{q}_i(t)$ are analytic functions.
\end{proof}

Consider the matrix
\begin{equation}\label{eq:Adef}
    A(t,s) = \tilde{A}_{-1}(t,s)\Theta(t-s) + \sum_{j=0}^k \tilde{A}_j(t)\delta^{(j)}(t-s) \in \mathcal{A}^{N \times M}(I)
\end{equation}
we define the Hermitian transpose of $A$ as
\begin{equation}\label{eq:AH}
    A^H(t,s) = \tilde{A}_{-1}^H(t,s)\Theta(t-s) + \sum_{j=0}^k \tilde{A}^H_j(t)\delta^{(j)}(t-s) \in \mathcal{A}^{M \times N}(I),
\end{equation}
with $\tilde{A}_j^H$ the usual Hermitian transpose of a matrix.
As an immediate consequence of Theorem~\ref{thm:stareig}, we have the following $\star$-factorization of $A(t,s)$.
%(note that in the following $q_j(t,s)^H = \tilde{q}_j(t)^H \Theta(t-s) + \tilde{q}_j(s)^H \delta(t-s)$).
\begin{corollary}\label{cor:stareigdec}
    Under the same assumption of Theorem~\ref{thm:stareig}, we have
    \begin{equation*}
    A(t,s) = Q(t,s) \star \Lambda(t,s) \star Q(t,s)^H,
\end{equation*}
with $\Lambda(t,s) = \tilde{\Lambda}(t)\Theta(t-s)$ and $Q(t,s)= [q_1(t,s), \dots, q_N(t,s)]$. Moreover, it holds
\begin{equation*}
    Q(t,s) \star Q(t,s)^H = Q(t,s)^H \star Q(t,s) = I_\star,
\end{equation*}
that is, $Q(t,s)^H$ is the matrix $\star$-inverse of $Q(t,s)$.
\end{corollary}
\begin{proof}
    We first show that for every $i,j=1,\dots,N$ we have
    \begin{equation*}
        q_i(t,s)^H \star q_j(t,s) = \delta_{ij} \delta(t-s),
    \end{equation*}
    with $\delta_{ij}$ the Kronecker delta. Since $q_k(t,s) = \delta'(t-s) \star \tilde{q}_k \Theta(t-s)$, for $k=1,\dots,N$, then
    \begin{align*}
        q_i(t,s)^H \star q_j(t,s) &= \big(\delta'(t-s) \star \tilde{q}_i^H(t) \Theta(t-s)\big) \star \big(\delta'(t-s) \star \tilde{q}_j(t) \Theta(t-s)\big) \\
            &= \delta'(t-s) \star \big( \tilde{q}_i^H(t) \Theta(t-s) \star \delta'(t-s) \big) \star \tilde{q}_j(t) \Theta(t-s) \\
            &= \delta'(t-s) \star \big(\tilde{q}_i^H(t)\delta(t-s) \star \tilde{q}_j(t) \Theta(t-s) \big) \\
            &= \delta'(t-s) \star \tilde{q}_i^H(t)\tilde{q}_j(t)\Theta(t-s) = \delta'(t-s) \star \delta_{ij}\Theta(t-s) \\
            &= \delta_{ij}\delta(t-s).
    \end{align*}
   From Theorem~\ref{thm:stareig} we get the equality
\begin{equation*}
    A(t,s) \star Q(t,s) = Q(t,s) \star \Lambda(t,s).
\end{equation*}
The conclusion follows from $\star$-multiplying from the right by $Q(t,s)^H$. 
\end{proof}

\bigskip

Since our final goal is to measure an error, we need to introduce a $\star$-inner product and the relative $\star$-norm. To this aim, we take inspiration from the results in \cite{Ry23}, but we develop them in a different direction. 
Following \cite{Ry23}, we define the \emph{$\star$-Hermitian-transpose} of $A(t,s)$ in \eqref{eq:Adef} as
\begin{equation*}
    A^{\star H}(t,s) := A^H(s,t) = \tilde{A}^H_{-1}(s,t)\Theta(s-t) + \sum_{j=0}^k\tilde{A}_{j}^H(s)\delta^{(j)}(s-t) \in \mathcal{A}^{M \times N}(I).
\end{equation*}
Roughly speaking, one has to take the usual Hermitian transpose and then swap the variable $t,s$. Note the difference with the Hermitian transpose \eqref{eq:AH}.
%substantially modify them. We first introduce the injections:
%\begin{align*}
%    \psi_L: \mathcal{D}^{N\times 1}(I) &\rightarrow \mathcal{D}^{N\times 1}(I) &  \psi_R: \mathcal{D}^{N\times 1}(I) &\rightarrow \mathcal{D}^{N\times 1}(I) \\
%    v(t,s) & \mapsto v(t,t) & v(t,s) & \mapsto v(s,s).
%\end{align*}
%Note that there exists $v \in \mathcal{D}^{N\times 1}(I)$ such that $v(t,s) \not\equiv 0$, but $v(t,t)\equiv 0$. For instance, $\Theta^{\star k}$ for $k = 2, 3, \dots$ . This constitutes a problem if we want to use the maps $\psi_L, \psi_R$ to define an inner product and a norm. We fix this problem by introducing the concept of \emph{$\star$-grade}.
%\begin{definition}
%    Give the non identically zero function $f \in \mathcal{A}_\Theta^{N \times M}$, we say that $f$ has \emph{$\star$-grade $d$} if
%    \begin{equation*}
%        (f \star \delta^{(j)})(t,t) \equiv 0, \; j= 0, \dots, d-1, \quad (f \star \delta^{(d)})(t,t) \not\equiv 0.
%    \end{equation*}
%\end{definition}
%Note that $d$ is always finite since, given $f(t,s) = \tilde{f}(t,s)\Theta(t-s) \in \mathcal{A}_\Theta^{N \times M}$,
%\begin{equation*}
%    f(t,s) \star \delta^{j}(t-s) = \tilde{f}^{(0,j)}(t,s)\Theta(t-s), \quad  j=0, \dots, d-1,
%\end{equation*}
%where $\tilde{f}^{(0,j)}$ stands for the $j$th derivative in $s$ of $\tilde{f}$. Therefore, if $d$ is not finite, then $\tilde{f}^{(0,j)}(t,t)\equiv 0$ for $j=0, 1, \dots$ . Hence, fixing $t$, the function $\tilde{f}(t,\cdot)$ has all derivative null at the point $t$. Since it is an analytic function, this means that $\tilde{f}(t,\cdot) \equiv 0$ for every $t$. Then, $f(t,s)$ is null for every $t,s \in I$. Moreover, note that 
%\begin{equation}\label{eq:gradeinAtheta}
%    f(t,s) \star \delta^{(d)}(t-s) = \tilde{f}^{(0,d)} \Theta(t-s) \in \mathcal{A}_\Theta^{N \times M}.
%\end{equation}
Now, setting $I = [a,b]$, 
%we can 
%equip the vector space $\{\mathcal{A}_\Theta^{N\times 1}(I), \star, +\}$ with 
%define an inner product. 
and given $v,w$ such that  $\Theta \star v, \Theta \star w \in \mathcal{A}_\Theta^{N\times 1}(I)$, for any fixed $s \in [a,b)$ we can define the inner product:
\begin{equation*}
    \langle v, w \rangle_\star(s) := \left( (\Theta \star v)^{\star H} \star \Theta \star w \right)(s,s) = \int_I v^H(\tau,s) w(\tau,s) \, \text{d}\tau.
\end{equation*}
Note that, denoting $\Theta(t-s) \star v(t,s) = \tilde{V}(t,s)\Theta(t-s)$ and $\Theta(t-s) \star w(t,s) = \tilde{W}(t,s)\Theta(t-s)$, then
\begin{equation*}
    \langle v, w \rangle_\star(s) =  \int_s^b \tilde{V}^H(\tau,s) \tilde{W}(\tau,s) \, \text{d}\tau,
\end{equation*}